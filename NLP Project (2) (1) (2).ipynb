{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a176ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"C:\\Users\\toqae\\Downloads\\review_polarity\\txt_sentoken\\pos\"\n",
    "folder_path2 = r\"C:\\Users\\toqae\\Downloads\\review_polarity\\txt_sentoken\\neg\"\n",
    "\n",
    "# Define an empty list to store the file contents\n",
    "file_contents = []\n",
    "file_value = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Open the file and read its content\n",
    "        with open(os.path.join(folder_path, filename), 'r') as file:\n",
    "            content = file.read()\n",
    "            # Append the content to the list\n",
    "            file_contents.append(content)\n",
    "            file_value.append(1)\n",
    "            \n",
    "            \n",
    "for filename in os.listdir(folder_path2):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Open the file and read its content\n",
    "        with open(os.path.join(folder_path2, filename), 'r') as file:\n",
    "            content = file.read()\n",
    "            # Append the content to the list\n",
    "            file_contents.append(content)\n",
    "            file_value.append(0)            \n",
    "\n",
    "# Create a data frame with the file contents\n",
    "df = pd.DataFrame({'Document': file_contents, 'review': file_value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b03879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Document  review\n",
      "0  films adapted from comic books have had plenty...       1\n",
      "1  every now and then a movie comes along from a ...       1\n",
      "2  you've got mail works alot better than it dese...       1\n",
      "3   \" jaws \" is a rare film that grabs your atten...       1\n",
      "4  moviemaking is a lot like being the general ma...       1\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2bf01cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Document  review\n",
      "1995  if anything , \" stigmata \" should be taken as ...       0\n",
      "1996  john boorman's \" zardoz \" is a goofy cinematic...       0\n",
      "1997  the kids in the hall are an acquired taste . \\...       0\n",
      "1998  there was a time when john carpenter was a gre...       0\n",
      "1999  two party guys bob their heads to haddaway's d...       0\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b0e2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ef54bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film adapt comic book plenti success , whether...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>everi movi come along suspect studio , everi i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>got mail work alot better deserv . order make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" jaw \" rare film grab attent show singl imag ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moviemak lot like gener manag nfl team post-sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  review\n",
       "0  film adapt comic book plenti success , whether...       1\n",
       "1  everi movi come along suspect studio , everi i...       1\n",
       "2  got mail work alot better deserv . order make ...       1\n",
       "3  \" jaw \" rare film grab attent show singl imag ...       1\n",
       "4  moviemak lot like gener manag nfl team post-sa...       1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from textblob import Word\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['Document'] = df['Document'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "stop = nltk.corpus.stopwords.words('english')\n",
    "df['Document'] = df['Document'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "st = PorterStemmer()\n",
    "df['Document'] = df['Document'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "df['Document'] =df['Document'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f063c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "Y=df['review']\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(Xnew,Y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d6c24121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01405813, 0.01784926, 0.01501924, ..., 0.0267836 , 0.01992206,\n",
       "       0.02926525])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf.fit(df['Document'])\n",
    "#applying tf idf to training data\n",
    "X_train_tf = tf_idf.fit_transform(x_train)\n",
    "\n",
    "#transforming test data into tf-idf matrix\n",
    "X_test_tf = tf_idf.transform(x_test)\n",
    "\n",
    "X_train_tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c0e93168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def train_model(classifier,X_train ,y_train, X_test,y_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # predict the labels on validation dataset\n",
    "    return accuracy_score(y_test, classifier.predict(X_test))\n",
    "   # return metrics.classification_report(y_test, predictions, target_names=['Positive', 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b6e07bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8075\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(alpha=0.2), X_train_tf, y_train,X_test_tf,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cd9ec144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Classifier\n",
    "accuracy = train_model(linear_model.LogisticRegression(), X_train_tf, y_train,X_test_tf,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2fab9063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8325\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "accuracy = train_model(svm.SVC(), X_train_tf, y_train,X_test_tf,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e1c4853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6375\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "accuracy = train_model(DecisionTreeClassifier(), X_train_tf, y_train,X_test_tf,y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cca13725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toqae\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "accuracy = train_model(KNeighborsClassifier(), X_train_tf, y_train,X_test_tf,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "871a06a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Review\n"
     ]
    }
   ],
   "source": [
    "test=['bad film']\n",
    "\n",
    "review = re.sub('[^a-zA-Z]', ' ', test[0])\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "test_processed =[ ' '.join(review)]\n",
    "test_input = tf_idf.transform(test_processed)\n",
    "\n",
    "\n",
    "#logistic regression\n",
    "clf = linear_model.LogisticRegression() \n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train_tf, y_train)\n",
    "#Predict the response for test dataset\n",
    "res = clf.predict(test_input)\n",
    "#print(accuracy)\n",
    "if res==1:\n",
    "    print(\"Good Review\")\n",
    "elif res==0:\n",
    "    print(\"Bad Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f09a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
